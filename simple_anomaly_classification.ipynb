{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b54c68e650ca17",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from copy import deepcopy\n",
    "from utils import slice_dataframe\n",
    "from helper import load_valid_norm_datasets_sorted_by_date\n",
    "from models import anomaly_classification\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load raw dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96de18344768e3fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터를 로드 합니다.\n",
    "_, norm_target_df, scalers = load_valid_norm_datasets_sorted_by_date('./pu_batt_sample.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "714e065cd6697313"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Generate trainable datasets\n",
    "- LSTM 모델에 작동 가능하도록 전처리 합니다.\n",
    "- 전처리 목록\n",
    "  1. N, N_col -> N/10, 10, N_col 형태로 변환합니다. (RNN 계열 데이터 포맷)\n",
    "  2. Anomaly data을 생성해 기존 정상 데이터 셋에 추가합니다. (정상 데이터 평균 1, 분산 1, 평균이 3이고 분산이 2인 anomaly data 추가)\n",
    "  3. 분류 데이터를 생성합니다.\n",
    "  4. 데이터를 섞습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6296885de2a39098"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터 일정한 크기와 간격으로 slice 합니다.\n",
    "steps = 10\n",
    "strides=10\n",
    "n_sample=None\n",
    "sliced_dfs = slice_dataframe(norm_target_df.iloc[:n_sample], interval=steps, stride=strides, output_type='numpy')\n",
    "print(np.mean(np.array(sliced_dfs)))\n",
    "\n",
    "ano_sliced_dfs = deepcopy(sliced_dfs)\n",
    "# anomlay dataset 을 생성합니다.\n",
    "for idx, sliced_df in enumerate(tqdm(ano_sliced_dfs)):\n",
    "    n_anomaly = np.random.randint(1, 100)  # outlier dataset 생성\n",
    "    index = []\n",
    "    rand_values = [] \n",
    "    # 데이터셋 내 random 한 위치와 random 한 개수로 anomaly dataset 삽입\n",
    "    for _ in range(n_anomaly):\n",
    "        timestep_idx = np.random.randint(0, 10)\n",
    "        col_idx = np.random.randint(0, 100)\n",
    "        index.append([timestep_idx, col_idx])\n",
    "    # anomlay value 생성\n",
    "    anomaly_mean, anomaly_std = 3, 2\n",
    "    rand_values = np.random.normal(anomaly_mean, anomaly_std, n_anomaly)\n",
    "    index = np.array(index)\n",
    "    sliced_df[index[:, 0], index[:, 1]] = rand_values\n",
    "    ano_sliced_dfs[idx] = sliced_df \n",
    "print(np.mean(ano_sliced_dfs), np.mean(sliced_dfs))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "630f2db48cbef962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_xs, train_ys\n",
    "train_xs = np.array(ano_sliced_dfs + sliced_dfs)\n",
    "train_ys = np.array([0]*len(ano_sliced_dfs) + [1]*len(sliced_dfs))\n",
    "del(ano_sliced_dfs)\n",
    "del(sliced_dfs)\n",
    "\n",
    "# shuffle \n",
    "shuffle_idx = np.arange(len(train_ys)) \n",
    "np.random.shuffle(shuffle_idx)\n",
    "train_xs = train_xs[shuffle_idx]\n",
    "train_ys = train_ys[shuffle_idx]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cfad0f47f9cc949"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('train_xs.npy', train_xs)\n",
    "np.save('train_ys.npy', train_ys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd6180fc93e777c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f89f3690526a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 예제 입력 및 출력 차원 및 은닉 유닛 수\n",
    "input_n_features = norm_target_df.shape[-1]\n",
    "hidden_units = 64\n",
    "\n",
    "# 모델 생성\n",
    "model = anomaly_classification(steps, input_n_features, hidden_units)\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "model.compile('adam', loss='sparse_categorical_crossentropy')\n",
    "model.save('./tmp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385e220574807a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_xs, train_ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = model.predict(train_xs)\n",
    "y_hat = np.argmax(y_hat, axis=-1)\n",
    "print('Accuracy: {}'.format(np.mean(y_hat == train_ys) * 100))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a0efaab26d3d70"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rice-detector_py3_9",
   "language": "python",
   "name": "rice-detector_py3_9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
